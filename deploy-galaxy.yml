---
# Optimized runtime playbook for single-node RKE2 deployments on pre-prepared Ubuntu 24.04+ images.
# This playbook assumes RKE2, Helm, and Helm repositories are pre-cached via image_prep.yml role.
# IMPORTANT: This playbook only works with Ubuntu 24.04+ images prepared by the image_preparation role.
#
# Features:
# - Single-node RKE2 cluster (master node runs workloads)
# - Pre-installed RKE2 binaries for faster deployment
# - Automatic taint removal for workload scheduling on master
# - Optimized for Galaxy deployment scenarios
# - Minimal fact gathering for maximum speed

- name: Runtime configuration and RKE2 cluster setup
  hosts: k8s_cluster
  gather_facts: true  # Only gather facts once at the very beginning
  tasks:
    # Initial system preparation tasks
    - name: Regenerate SSH host keys
      shell: |
        ssh-keygen -A
        systemctl restart ssh
      become: true

    - name: Start required services
      systemd:
        name: "{{ item }}"
        state: started
        enabled: true
        daemon_reload: true
      loop:
        - containerd
        - autofs
      become: true

    - name: Initialize machine-id
      shell: systemd-machine-id-setup
      become: true

    - name: Ensure user kubeconfig directory
      file:
        path: "{{ ansible_env.HOME }}/.kube"
        state: directory
        owner: "{{ ansible_user_id }}"
        group: "{{ ansible_user_gid }}"
        mode: '0755'
      become: true

    - name: Create RKE2 server configuration for single-node cluster
      copy:
        dest: /etc/rancher/rke2/config.yaml
        mode: '0600'
        content: |
          write-kubeconfig-mode: "0644"
          cluster-init: true
          token: "{{ rke2_token }}"
          advertise-address: "{{ ansible_default_ipv4.address }}"
          tls-san:
            - "{{ ansible_default_ipv4.address }}"
            - "{{ ansible_ssh_host | default(ansible_host) }}"
            - 127.0.0.1
            - localhost
            - 0.0.0.0
          {% for san in rke2_additional_sans | default([]) %}
            - "{{ san }}"
          {% endfor %}
          bind-address: "0.0.0.0"
          disable:
          {% for component in rke2_disable | default(['rke2-traefik', 'rke2-ingress-nginx']) %}
            - "{{ component }}"
          {% endfor %}
          cni:
            - canal
          {% if rke2_debug | default(false) %}
          debug: true
          {% endif %}
      become: true

    - name: Start and enable RKE2 server
      systemd:
        name: rke2-server
        state: started
        enabled: true
        daemon_reload: true
      become: true

    - name: Wait for RKE2 server to be ready
      wait_for:
        port: 6443
        host: "{{ ansible_default_ipv4.address }}"
        delay: 10
        timeout: 300

    - name: Wait for kubeconfig to be generated
      wait_for:
        path: /etc/rancher/rke2/rke2.yaml
        timeout: 60

    - name: Also fix any 0.0.0.0 references in original kubeconfig (fallback)
      replace:
        path: /etc/rancher/rke2/rke2.yaml
        regexp: 'server: https://0\.0\.0\.0:6443'
        replace: "server: https://{{ ansible_default_ipv4.address }}:6443"
      become: true

    - name: Fix kubeconfig server address for SSH connections
      replace:
        path: /etc/rancher/rke2/rke2.yaml
        regexp: "server: https://{{ ansible_default_ipv4.address }}:6443"
        replace: "server: https://127.0.0.1:6443"
      become: true
      when: ansible_connection != 'local'

    - name: Remove master node taint to allow workload scheduling
      shell: |
        /var/lib/rancher/rke2/bin/kubectl --kubeconfig /etc/rancher/rke2/rke2.yaml taint nodes --all node-role.kubernetes.io/control-plane- || true
        /var/lib/rancher/rke2/bin/kubectl --kubeconfig /etc/rancher/rke2/rke2.yaml taint nodes --all node-role.kubernetes.io/master- || true
      become: true

    - name: Copy kubeconfig to user
      copy:
        src: /etc/rancher/rke2/rke2.yaml
        dest: "{{ ansible_env.HOME }}/.kube/config"
        owner: "{{ ansible_user_id }}"
        group: "{{ ansible_user_gid }}"
        mode: '0600'
        remote_src: true
      become: true

    - name: Make root kubeconfig readable by ubuntu user for ansible-pull
      file:
        path: /root/.kube/config
        group: ubuntu
        mode: '0640'
      become: true
      when: ansible_connection == 'local'

    - name: Fix user kubeconfig for SSH connections
      replace:
        path: "{{ ansible_env.HOME }}/.kube/config"
        regexp: "server: https://{{ ansible_default_ipv4.address }}:6443"
        replace: "server: https://127.0.0.1:6443"
      become: true
      when: ansible_connection != 'local'

    - name: Also fix any 0.0.0.0 references in user kubeconfig (fallback)
      replace:
        path: "{{ ansible_env.HOME }}/.kube/config"
        regexp: 'server: https://0\.0\.0\.0:6443'
        replace: "server: https://{{ ansible_default_ipv4.address }}:6443"
      become: true
      when: ansible_connection == 'local'

    - name: Add RKE2 bin directory to user's PATH
      lineinfile:
        path: "{{ ansible_env.HOME }}/.bashrc"
        line: 'export PATH=/var/lib/rancher/rke2/bin:$PATH'
        create: true
        owner: "{{ ansible_user_id }}"
        group: "{{ ansible_user_gid }}"
        mode: '0644'
      become: true

    - name: Add KUBECONFIG to user's environment
      lineinfile:
        path: "{{ ansible_env.HOME }}/.bashrc"
        line: "export KUBECONFIG={{ ansible_env.HOME }}/.kube/config"
        create: true
        owner: "{{ ansible_user_id }}"
        group: "{{ ansible_user_gid }}"
        mode: '0644'
      become: true

    # Ensure kubeconfig is available for ansible kubernetes modules
    - name: Set kubeconfig path fact for local connections
      set_fact:
        kubeconfig_path: "{{ ansible_env.HOME }}/.kube/config:/root/.kube/config"
      when: ansible_connection == 'local'

    - name: Set kubeconfig path fact for SSH connections
      set_fact:
        kubeconfig_path: "{{ ansible_env.HOME }}/.kube/config"
      when: ansible_connection != 'local'

- name: Install NFS
  import_playbook: nfs.yml

- name: Configure storage
  import_playbook: storage.yml

- name: Configure Ingress
  import_playbook: ingress.yml

- name: Install Galaxy
  import_playbook: galaxy_app.yml
  vars:
    values_file: "values/{{ chart_values_file | default('values.yml') }}"
    gxy_admin_users: "{{ galaxy_admin_users | default('') }}"
